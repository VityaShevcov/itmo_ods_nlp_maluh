\documentclass{article}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{mathtext}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{rotating}
\usepackage{makecell}
\renewcommand\theadfont{\bfseries}


\title{Сравнительный анализ методов тематического моделирования LDA и BERTopic на корпусе русскоязычных банковских отзывов}
\author{Валентин Малых}
\date{Май 2024}



\begin{document}
\maketitle
\begin{abstract}
    В данной работе представлен сравнительный анализ двух методов тематического моделирования: латентного размещения Дирихле (LDA) и BERTopic. Анализ проведен на корпусе русскоязычных отзывов о банковских услугах. Основной вклад работы заключается в разработке и применении комплексной методологии оценки, включающей композитную метрику и сравнение моделей при равном количестве тем, что позволяет провести более объективное сравнение в прикладном контексте. Результаты показывают, что BERTopic демонстрирует значительное преимущество в качестве тематик (композитная оценка 1.250 против 0.686 у LDA), однако уступает в полноте покрытия данных (59.6\% против 100\%). В работе делается вывод о компромиссе между качеством тем и полнотой охвата данных, а также предлагается гибридный подход для решения практических бизнес-задач. Ссылка на код проекта: \url{https://github.com/username/itmo_ods_nlp_maluh}.
\end{abstract}



\section{Введение}
Анализ клиентских отзывов является одной из ключевых задач для современных компаний, стремящихся улучшить качество своих продуктов и услуг. Тематическое моделирование предоставляет инструментарий для автоматической обработки больших объемов неструктурированных текстовых данных и выявления в них основных тем. Однако сравнение различных методов тематического моделирования часто осложняется отсутствием единых стандартов оценки и влиянием таких факторов, как итоговое количество тем.

Целью данной работы является проведение исчерпывающего сравнительного анализа классического вероятностного подхода (LDA) и современного метода на основе трансформеров (BERTopic) на реальных бизнес-данных.

Следует отметить, что данная работа не претендует на создание нового метода тематического моделирования. Её научная ценность заключается в методологическом вкладе: разработке и апробации комплексного подхода к сравнительному анализу существующих моделей. Основное внимание уделяется не поиску "лучшей" модели в вакууме, а демонстрации их сильных и слабых сторон для решения конкретных бизнес-задач.
\subsection{Команда}
\textbf{Валентин Малых} подготовил данный документ и провел исследование.



\section{Обзор связанных работ}
\label{sec:related}
В области тематического моделирования можно выделить два доминирующих направления.

\textbf{Вероятностные тематические модели.} Данное направление берет свое начало с работы \cite{blei2003latent}, в которой был предложен метод латентного размещения Дирихле (LDA). LDA является генеративной вероятностной моделью, которая предполагает, что каждый документ представляет собой смесь тем, а каждая тема — распределение на словаре. Несмотря на появление более сложных методов, LDA до сих пор остается популярным базовым подходом благодаря своей интерпретируемости и эффективности.

\textbf{Модели на основе нейронных сетей и эмбеддингов.} С развитием трансформерных архитектур появились новые подходы. Одним из наиболее заметных является BERTopic \cite{grootendorst2022bertopic}, который объединяет получение семантических представлений текстов (эмбеддингов) с помощью моделей типа BERT, последующее снижение размерности и кластеризацию. Этот подход позволяет улавливать семантическую близость текстов, а не только их лексическое сходство.

\textbf{Проблема оценки качества.} Объективная оценка качества тематических моделей является сложной задачей. Наиболее распространенные метрики, такие как когерентность тем (topic coherence) \cite{roder2015exploring}, хорошо зарекомендовали себя для вероятностных моделей, но их применимость к моделям типа BERTopic ограничена. В ряде современных работ, например в обзоре \cite{egger2022evaluating}, подчеркивается необходимость использования нескольких метрик для формирования комплексной оценки, что и послужило мотивацией для методологии данного исследования.

\section{Методология}
\label{sec:methodology}
Для объективного сравнения моделей была разработана методология, направленная на минимизацию смещений при оценке.

\subsection{Композитная метрика оценки}
Использование единственной метрики может привести к неверным выводам. Например, высокая когерентность тем может быть достигнута при неполном покрытии данных, что снижает практическую ценность модели. Для комплексной оценки была разработана взвешенная композитная метрика, учитывающая четыре аспекта качества модели:

$$
\text{Score} = w_1 \cdot \text{C}_{v} + w_2 \cdot \text{Sil} + w_3 \cdot \text{Cov} + w_4 \cdot \text{Div}
$$
где компоненты:
\begin{itemize}
    \item \textbf{Когерентность ($C_v$, вес: 0.35):} Семантическая связность и интерпретируемость тем. Используется метрика C\_v.
    \item \textbf{Коэффициент силуэта (Sil, вес: 0.25):} Качество разделения тем в пространстве эмбеддингов.
    \item \textbf{Покрытие (Cov, вес: 0.25):} Доля документов, отнесенных к какой-либо теме (критично для бизнес-применения).
    \item \textbf{Разнообразие (Div, вес: 0.15):} Уникальность тем, измеряемая через когерентность UMass для штрафа за лексические пересечения.
\end{itemize}

\subsection{Протокол справедливого сравнения}
Помимо композитной метрики, был применен дополнительный шаг для обеспечения справедливости сравнения. После определения оптимального количества тем для BERTopic, модель LDA была обучена с тем же фиксированным количеством тем. Это позволяет напрямую сравнить качество моделей, устранив влияние количества тем как переменной.

\section{Набор данных и его анализ}
В исследовании используется корпус русскоязычных отзывов о банковских услугах, собранный из открытых интернет-источников (Banki.ru, 2GIS). Данные не были предварительно размечены и представляют собой реальный сценарий для неконтролируемого анализа.

\subsection{Статистики и репрезентативность}
Ключевые статистики набора данных представлены в Таблице~\ref{tab:dataset_stats}. Для оценки репрезентативности был проведен дополнительный анализ. Распределение длин документов имеет правостороннюю асимметрию: большинство отзывов короткие (медиана — 75 токенов), но присутствует "хвост" из очень длинных текстов, что типично для пользовательского контента. Корпус сбалансирован по источникам (52\% с Banki.ru, 48\% с 2GIS), что делает его относительно однородным.

\begin{table}[tbh!]
\centering
\begin{tabular}{lc}
\toprule
\textbf{Параметр} & \textbf{Значение} \\
\midrule
Количество документов & 5,646 \\
Язык & Русский \\
Источники & Публичные агрегаторы отзывов \\
Средняя длина документа (токены) & 98 \\
Размер словаря (лемматизированный) & 19,872 \\
\bottomrule
\end{tabular}
\caption{Ключевые статистики набора данных.}
\label{tab:dataset_stats}
\end{table}

Были применены стандартные шаги предобработки, включая токенизацию, лемматизацию и удаление стоп-слов.

\section{Эксперименты и результаты}
Экспериментальный процесс включал оптимизацию гиперпараметров для LDA и BERTopic по композитной метрике, после чего последовал этап справедливого сравнения и качественный анализ полученных тем.

\subsection{Настройка экспериментов}
Для обеспечения воспроизводимости ниже представлены детали настройки экспериментов. Поиск оптимальных гиперпараметров осуществлялся методом сеточного поиска (Grid Search).

\textbf{Для LDA} варьировалось количество тем, как основной гиперпараметр:
\begin{itemize}
    \item \texttt{num\_topics} $\in \{10, 15, 20, 25, 30, 35\}$
    \item Остальные параметры были зафиксированы: \texttt{alpha='symmetric'}, \texttt{eta='auto'}, \texttt{passes=10}.
\end{itemize}

\textbf{Для BERTopic} ключевым параметром был минимальный размер кластера:
\begin{itemize}
    \item \texttt{min\_cluster\_size} $\in \{5, 10, 15, 20, 25\}$
    \item Модель кластеризации: HDBSCAN, модель снижения размерности: UMAP.
\end{itemize}


\subsection{Количественные результаты}
Сравнение трех моделей — оптимальной LDA, оптимальной BERTopic и LDA с фиксированным числом тем — дало результаты, представленные в Таблице~\ref{tab:main_results}. BERTopic является безусловным лидером по композитной оценке. Однако его основной слабостью является неполное покрытие данных. Справедливое сравнение BERTopic и LDA при 54 темах подтверждает качественное превосходство первого даже в равных условиях.

\begin{table}[tbh!]
\centering
\caption{Основные количественные результаты сравнения моделей.}
\label{tab:main_results}
\begin{tabular}{l ccc}
\toprule
\thead{Метрика} & \thead{BERTopic \\ (Оптимальная)} & \thead{LDA \\ (Фикс., 54 темы)} & \thead{LDA \\ (Оптимальная)} \\
\midrule
Композитная оценка & \textbf{1.250} & 0.699 & 0.686 \\
Когерентность (Cv)  & 0.556 & 0.465 & 0.467 \\
Покрытие            & 59.6\% & 100\% & 100\% \\
Количество тем      & 54 & 54 & 25 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Качественный анализ}
Автоматизированные метрики не могут полностью заменить ручной анализ с участием человека. Качественный анализ сгенерированных тем выявляет дальнейшие различия. Для более детального ознакомления с качеством тем и примерами текстов из соответствующих кластеров, пожалуйста, обратитесь к Приложению А. В Таблице~\ref{tab:output_samples} приведены обобщенные примеры тем, сгенерированных обеими моделями.

\textbf{Анализ LDA:} Оптимальная модель LDA (25 тем) формирует семантически связные, но широкие и обобщенные категории. Например, тема "Кредитные продукты" логически группирует связанные ключевые слова, но смешивает разные настроения и намерения пользователей (например, жалобы на ставки, вопросы по договорам, положительные отзывы). Это полезно для общего обзора, но не хватает гранулярности для целенаправленных действий.

\textbf{Анализ BERTopic:} BERTopic (54 темы) предоставляет значительно более детализированную картину. Он выявляет узкоспециализированные и практически полезные темы. Однако главным недостатком является огромное количество выбросов — \textbf{40.4\% документов не были отнесены ни к одной теме}. Это является критическим ограничением для бизнеса, так как значительная часть обратной связи остается необработанной.

\textbf{Практическое решение проблемы выбросов:} На практике для достижения полного покрытия документы-выбросы можно принудительно распределить по существующим темам на основе косинусного расстояния до центроида каждой темы в пространстве эмбеддингов. Это компромиссный подход, позволяющий сохранить гранулярные темы BERTopic и при этом не терять данные.

\begin{table}[!tbh]
    \centering
    \begin{tabular}{|p{0.9\linewidth}|}
\hline
\textbf{Тема LDA: Кредитные продукты (Общая)} \\
\small\textit{Ключевые слова: кредит, ипотека, ставка, договор, банк, одобрение, заявка} \\
\hline
\textbf{Тема BERTopic: Проблемы с аутентификацией в мобильном приложении (Специфичная)} \\
\small\textit{Ключевые слова: приложение, войти, пароль, смс, код, ошибка, телефон} \\
\hline
    \end{tabular}
    \caption{Примеры тем из LDA и BERTopic, иллюстрирующие разницу в гранулярности.}
    \label{tab:output_samples}
\end{table}


\section{Заключение и ограничения}
В данной работе был проведен сравнительный анализ методов LDA и BERTopic с использованием надежной методологии оценки.

\subsection{Основные выводы}
\begin{enumerate}
    \item Современный подход BERTopic демонстрирует значительное преимущество в качестве и гранулярности тем по сравнению с классической моделью LDA.
    \item Это преимущество достигается ценой неполного охвата данных, что является критическим ограничением для многих бизнес-приложений.
    \item Предложенная композитная метрика и протокол "справедливого сравнения" позволяют проводить более объективную и сбалансированную оценку тематических моделей.
\end{enumerate}

\subsection{Ограничения и дальнейшие шаги}
Несмотря на полученные результаты, работа имеет ряд ограничений, которые открывают направления для дальнейших исследований:
\begin{itemize}
    \item \textbf{Чувствительность весов:} Не был проведен анализ чувствительности весов композитной метрики. Исследование того, как изменение весов на $\pm10-20\%$ повлияет на итоговый рейтинг моделей, является важным шагом для валидации метрики.
    \item \textbf{Нормализация метрик:} В текущей реализации компоненты метрики агрегировались без предварительной нормализации, что может вносить смещение из-за разных шкал. В будущих работах следует применять, например, min-max нормализацию для каждой метрики перед взвешенным суммированием.
    \item \textbf{Гибридный подход:} Предложенный гибридный подход (BERTopic + распределение выбросов по косинусному расстоянию) требует отдельной экспериментальной проверки и оценки качества.
\end{itemize}

Ключевой практический вывод заключается в том, что выбор модели не может основываться исключительно на автоматизированных метриках. Применение в реальном бизнес-контексте требует качественной оценки с привлечением отраслевых экспертов. Оптимальной стратегией может быть гибридный подход, объединяющий сильные стороны обеих моделей — аналитическую глубину BERTopic и надежность полного покрытия LDA.

\appendix
\section{Примеры тем и соответствующих документов}

\subsection{Примеры тем модели LDA}

\subsubsection{Тема: Кредитные продукты}
\textbf{Ключевые слова:} кредит, ипотека, ставка, договор, банк, одобрение, заявка
\begin{quote}
\small
\textit{Пример 1: "Очень долго рассматривали заявку на ипотеку, в итоге одобрили под более высокий процент, чем обещали. Договор пришлось перечитывать несколько раз."} \\
\textit{Пример 2: "Спасибо за рефинансирование кредита! Ставка стала гораздо ниже, ежемесячный платеж уменьшился. Процесс был быстрый и понятный."}
\end{quote}

\subsubsection{Тема: Обслуживание в отделениях}
\textbf{Ключевые слова:} очередь, сотрудник, отделение, окно, время, ожидание, талон
\begin{quote}
\small
\textit{Пример 1: "Просидел в очереди почти час, хотя народу было немного. Работало всего два окна из пяти, сотрудники еле двигались."} \\
\textit{Пример 2: "Хочу выразить благодарность сотруднице Ольге в отделении на Ленинском проспекте. Помогла решить проблему с картой, все объяснила, была очень вежлива."}
\end{quote}

\subsection{Примеры тем модели BERTopic}

\subsubsection{Тема: Проблемы с аутентификацией в мобильном приложении}
\textbf{Ключевые слова:} приложение, войти, пароль, смс, код, ошибка, телефон
\begin{quote}
\small
\textit{Пример 1: "После обновления приложения не могу войти. Пишет 'неверный пароль', хотя я его не менял. Сброс пароля через СМС не работает, код не приходит."} \\
\textit{Пример 2: "Почему для входа в приложение каждый раз нужно вводить код из СМС? Это неудобно, сделайте вход по отпечатку пальца!"}
\end{quote}

\subsubsection{Тема: Благодарность за помощь с ипотекой}
\textbf{Ключевые слова:} спасибо, благодарность, менеджер, ипотека, помощь, быстро
\begin{quote}
\small
\textit{Пример 1: "Огромное спасибо ипотечному менеджеру Анне! Помогла собрать все документы, всегда была на связи, сделка прошла очень быстро и гладко."} \\
\textit{Пример 2: "Выражаю благодарность банку за одобрение ипотеки и отдельное спасибо нашему менеджеру за профессионализм и терпение. Мы очень довольны!"}
\end{quote}

\subsubsection{Тема: Проблемы с оплатой по QR-коду}
\textbf{Ключевые слова:} qr, код, оплата, терминал, не проходит, касса, магазин
\begin{quote}
\small
\textit{Пример 1: "Пытался оплатить покупку в магазине через ваш QR-код, но платеж не прошел. Кассир говорит, что терминал исправен, проблема на стороне банка."} \\
\textit{Пример 2: "Не сработала оплата по QR-коду на заправке. Пришлось платить другой картой. Очень неудобно, исправьте пожалуйста."}
\end{quote}

\bibliographystyle{apalike}
\bibliography{references}
\end{document} 